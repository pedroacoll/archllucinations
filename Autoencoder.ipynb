{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgDrB90Vw_n",
        "colab_type": "code",
        "outputId": "56f17341-b4a4-4b0a-8d96-94162f989294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_ZTNwIrLiD",
        "colab_type": "code",
        "outputId": "5c187b5a-a678-4b89-a4e0-413b7dd576bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Reshape, Conv2DTranspose\n",
        "from keras.models import Model ,Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C205la_quPs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load('/content/drive/My Drive/1260_mercator/mercator_total.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6iGztIrdr9S",
        "colab_type": "code",
        "outputId": "41a5ff52-6504-4699-ae29-d15bb8b7a9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "plt.imshow(x_train[120],vmin=-1,vmax=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe4b7644198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACVCAYAAABB56G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4BC/S/XOV81LdmFAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZsq3dXLCMHO",
        "colab_type": "code",
        "outputId": "1919fdea-6b40-4048-b798-21f7351ba907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_au = np.expand_dims(x_train,axis=-1)\n",
        "print(x_train_au.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57461, 21, 60, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbiPPDLMY16w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder_implementation:\n",
        "\n",
        "  encoder=Sequential()\n",
        "  decoder=Sequential()\n",
        "  autoencoder=Sequential()\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    #creating encoder\n",
        "    self.encoder=Sequential()\n",
        "\n",
        "    self.encoder.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),input_shape=(21,60,1), activation='tanh',name='e_conv2d_1'))\n",
        "    #self.encoder.add(LeakyReLU(alpha=0.2))\n",
        "    self.encoder.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),name='e_maxpool_1'))\n",
        "    \n",
        "    self.encoder.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='tanh',name='e_conv2d_2'))\n",
        "    #self.encoder.add(LeakyReLU(alpha=0.2))\n",
        "    self.encoder.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),name='e_maxpool_2'))\n",
        "    \n",
        "    self.encoder.add(Flatten())\n",
        "    self.encoder.add(Dense(units=128, activation='tanh'))\n",
        "    self.encoder.add(BatchNormalization())\n",
        "    \n",
        "    self.encoder.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "    self.encoder.name='encoder'\n",
        "    self.encoder.summary()\n",
        "\n",
        "    #creating decoder\n",
        "    self.decoder=Sequential()\n",
        "\n",
        "    self.decoder.add(Dense(128 * 5 * 3, input_dim=128, name='dense'))\n",
        "    self.decoder.add(BatchNormalization())\n",
        "    self.decoder.add(Reshape((3, 5, 128), name='reshape'))\n",
        "\n",
        "    self.decoder.add(Conv2DTranspose(64, (5,5), strides=(7,3), padding='same', name='conv2dt_1'))\n",
        "    self.decoder.add(Conv2DTranspose(1, (5,5), strides=(1,4), padding='same', name='conv2dt_2'))\n",
        "\n",
        "    self.decoder.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "    self.decoder.name='decoder'\n",
        "    self.decoder.summary()\n",
        "\n",
        "    #creating autoencoder\n",
        "    autoencoder_input = Input(shape=(21,60,1))\n",
        "    x = self.encoder(autoencoder_input)\n",
        "    autoencoder_output=self.decoder(x)\n",
        "    self.autoencoder = Model(inputs=[autoencoder_input], outputs=autoencoder_output)\n",
        "    self.autoencoder.compile(loss='mse', optimizer='adam')\n",
        "    self.autoencoder.name='autoencoder'\n",
        "    self.autoencoder.summary()\n",
        "\n",
        "  def train(self, x_train, y_train, batch_size, epochs):\n",
        "    contador = 0\n",
        "    minloss = 1\n",
        "    while(contador < epochs):\n",
        "      print(\"\")\n",
        "      print(\"epoca {} de {}\".format(contador,epochs))\n",
        "      history = self.autoencoder.fit(x_train, y_train, batch_size, 1)\n",
        "      nloss = history.history['loss'][0]\n",
        "      print(nloss)\n",
        "      if contador == 0 or nloss<minloss:\n",
        "          self.autoencoder.save(\"autoencoder_definitivo.h5\")\n",
        "          self.encoder.save(\"encoder_definitivo.h5\")\n",
        "          self.decoder.save(\"decoder_definitivo.h5\")\n",
        "          minloss = nloss\n",
        "          print(\"\")\n",
        "          print(\"Saved model to disk\")\n",
        "          print(\"\")\n",
        "    \n",
        "      contador += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L01rNUGab-WI",
        "colab_type": "code",
        "outputId": "f6747413-645f-4710-f080-572e691a5db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "autoen = autoencoder_implementation()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "e_conv2d_1 (Conv2D)          (None, 17, 56, 32)        832       \n",
            "_________________________________________________________________\n",
            "e_maxpool_1 (MaxPooling2D)   (None, 16, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "e_conv2d_2 (Conv2D)          (None, 12, 51, 32)        25632     \n",
            "_________________________________________________________________\n",
            "e_maxpool_2 (MaxPooling2D)   (None, 11, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 17600)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               2252928   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 128)               512       \n",
            "=================================================================\n",
            "Total params: 2,279,904\n",
            "Trainable params: 2,279,648\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1920)              247680    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1920)              7680      \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 3, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2dt_1 (Conv2DTranspose)  (None, 21, 15, 64)        204864    \n",
            "_________________________________________________________________\n",
            "conv2dt_2 (Conv2DTranspose)  (None, 21, 60, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 461,825\n",
            "Trainable params: 457,985\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 21, 60, 1)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Sequential)         (None, 128)               2279904   \n",
            "_________________________________________________________________\n",
            "decoder (Sequential)         (None, 21, 60, 1)         461825    \n",
            "=================================================================\n",
            "Total params: 2,741,729\n",
            "Trainable params: 2,737,633\n",
            "Non-trainable params: 4,096\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMoCU0v1fR50",
        "colab_type": "code",
        "outputId": "854eca78-2194-4c06-e3e4-d388449a8a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "historial = autoen.train(x_train_au,x_train_au,256,4000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoca 0 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 14s 252us/step - loss: 0.1208\n",
            "0.12084309934990946\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 1 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 228us/step - loss: 0.0418\n",
            "0.04181834171359014\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 2 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0348\n",
            "0.03477867430017687\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 3 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0318\n",
            "0.0317948310520924\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 4 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0301\n",
            "0.030086177680231353\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 5 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0292\n",
            "0.029175047361303146\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 6 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0284\n",
            "0.028405069799605297\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 7 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0278\n",
            "0.02781880133133928\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 8 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0275\n",
            "0.02754115126287954\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 9 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0268\n",
            "0.02681517896946884\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 10 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0265\n",
            "0.026458549713469063\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 11 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 222us/step - loss: 0.0263\n",
            "0.026283689186695835\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 12 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0263\n",
            "0.026325219729227235\n",
            "\n",
            "epoca 13 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0260\n",
            "0.02604703881043329\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 14 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0259\n",
            "0.025879400855919645\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 15 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0255\n",
            "0.025527403322763174\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 16 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0258\n",
            "0.025845224381212017\n",
            "\n",
            "epoca 17 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0256\n",
            "0.02558275492961805\n",
            "\n",
            "epoca 18 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0254\n",
            "0.025355329221331605\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 19 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0250\n",
            "0.024996253831880925\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 20 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0250\n",
            "0.024992981247176135\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 21 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0250\n",
            "0.02502745491769396\n",
            "\n",
            "epoca 22 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0250\n",
            "0.025021187194305426\n",
            "\n",
            "epoca 23 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0248\n",
            "0.024780790423428026\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 24 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0248\n",
            "0.02477429347105222\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 25 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0249\n",
            "0.024930707965433795\n",
            "\n",
            "epoca 26 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0248\n",
            "0.02482210735257791\n",
            "\n",
            "epoca 27 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0246\n",
            "0.024563302520222145\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 28 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0246\n",
            "0.02462765137956862\n",
            "\n",
            "epoca 29 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0247\n",
            "0.024705529401190297\n",
            "\n",
            "epoca 30 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0244\n",
            "0.024407571727472425\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 31 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0244\n",
            "0.024435599921572185\n",
            "\n",
            "epoca 32 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0247\n",
            "0.024671194776852465\n",
            "\n",
            "epoca 33 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0861\n",
            "0.08606490847320093\n",
            "\n",
            "epoca 34 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0683\n",
            "0.06826145949287529\n",
            "\n",
            "epoca 35 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0611\n",
            "0.06110538072046847\n",
            "\n",
            "epoca 36 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0567\n",
            "0.056658733760358224\n",
            "\n",
            "epoca 37 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0559\n",
            "0.05594268556548693\n",
            "\n",
            "epoca 38 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0467\n",
            "0.04666727690090639\n",
            "\n",
            "epoca 39 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0394\n",
            "0.039440313055487654\n",
            "\n",
            "epoca 40 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 227us/step - loss: 0.0315\n",
            "0.031473282840635115\n",
            "\n",
            "epoca 41 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0286\n",
            "0.028564229108962023\n",
            "\n",
            "epoca 42 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0269\n",
            "0.026863809490726764\n",
            "\n",
            "epoca 43 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0425\n",
            "0.04251720797992048\n",
            "\n",
            "epoca 44 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0565\n",
            "0.056525382324302466\n",
            "\n",
            "epoca 45 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0439\n",
            "0.04394528258273113\n",
            "\n",
            "epoca 46 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0288\n",
            "0.028790226727202828\n",
            "\n",
            "epoca 47 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0259\n",
            "0.025869692989473378\n",
            "\n",
            "epoca 48 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0254\n",
            "0.025352721102714013\n",
            "\n",
            "epoca 49 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0249\n",
            "0.02491939997107988\n",
            "\n",
            "epoca 50 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0286\n",
            "0.028621402999191987\n",
            "\n",
            "epoca 51 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0255\n",
            "0.02545831533819341\n",
            "\n",
            "epoca 52 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0247\n",
            "0.024685225645439863\n",
            "\n",
            "epoca 53 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0246\n",
            "0.02458337920471162\n",
            "\n",
            "epoca 54 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0243\n",
            "0.024328830343875216\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 55 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0242\n",
            "0.024220412864944498\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 56 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0244\n",
            "0.024360264337157385\n",
            "\n",
            "epoca 57 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0243\n",
            "0.024301666490060284\n",
            "\n",
            "epoca 58 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0242\n",
            "0.024233312021834427\n",
            "\n",
            "epoca 59 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0245\n",
            "0.024498939112625455\n",
            "\n",
            "epoca 60 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0242\n",
            "0.0241987997384081\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 61 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0241\n",
            "0.024113501605467276\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 62 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0241\n",
            "0.024068193271075698\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 63 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0241\n",
            "0.0241341941535213\n",
            "\n",
            "epoca 64 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0240\n",
            "0.024002010424526862\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 65 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0240\n",
            "0.024020387347405695\n",
            "\n",
            "epoca 66 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0240\n",
            "0.024000126369866336\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 67 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0241\n",
            "0.024060543053726992\n",
            "\n",
            "epoca 68 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0240\n",
            "0.02404969835472729\n",
            "\n",
            "epoca 69 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0240\n",
            "0.02397682243461084\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 70 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0238\n",
            "0.023813658018041885\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 71 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0240\n",
            "0.02399460428306255\n",
            "\n",
            "epoca 72 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0293\n",
            "0.029308750643153796\n",
            "\n",
            "epoca 73 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0348\n",
            "0.03476765668432792\n",
            "\n",
            "epoca 74 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0240\n",
            "0.023968716575054942\n",
            "\n",
            "epoca 75 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0238\n",
            "0.02382413272714253\n",
            "\n",
            "epoca 76 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0239\n",
            "0.023874846021732052\n",
            "\n",
            "epoca 77 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0239\n",
            "0.023925968255702534\n",
            "\n",
            "epoca 78 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0237\n",
            "0.023673465064277827\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 79 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0237\n",
            "0.023725448583601896\n",
            "\n",
            "epoca 80 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 222us/step - loss: 0.0237\n",
            "0.023732286437577525\n",
            "\n",
            "epoca 81 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0239\n",
            "0.023857637589113048\n",
            "\n",
            "epoca 82 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.023621787964878627\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 83 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0238\n",
            "0.0238017696521345\n",
            "\n",
            "epoca 84 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0238\n",
            "0.02375737255862286\n",
            "\n",
            "epoca 85 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0239\n",
            "0.023864905689968366\n",
            "\n",
            "epoca 86 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 228us/step - loss: 0.0237\n",
            "0.02371071750867591\n",
            "\n",
            "epoca 87 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0237\n",
            "0.02366325856204262\n",
            "\n",
            "epoca 88 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0237\n",
            "0.023697771211962156\n",
            "\n",
            "epoca 89 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0236\n",
            "0.023641440656374364\n",
            "\n",
            "epoca 90 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 227us/step - loss: 0.0238\n",
            "0.02377082409299528\n",
            "\n",
            "epoca 91 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0237\n",
            "0.023679481701991623\n",
            "\n",
            "epoca 92 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0239\n",
            "0.023916347317386056\n",
            "\n",
            "epoca 93 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 227us/step - loss: 0.0236\n",
            "0.023616139901951477\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 94 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0630\n",
            "0.06297590354908175\n",
            "\n",
            "epoca 95 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0505\n",
            "0.05048217014087956\n",
            "\n",
            "epoca 96 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0440\n",
            "0.044003655540248876\n",
            "\n",
            "epoca 97 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0253\n",
            "0.025305015108541315\n",
            "\n",
            "epoca 98 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0241\n",
            "0.024091350537475045\n",
            "\n",
            "epoca 99 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0237\n",
            "0.023737140458582686\n",
            "\n",
            "epoca 100 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0238\n",
            "0.023837497918134058\n",
            "\n",
            "epoca 101 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0237\n",
            "0.023691127667588095\n",
            "\n",
            "epoca 102 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0235\n",
            "0.02352273637056973\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 103 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0235\n",
            "0.02347251398860397\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 104 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.023570836994939816\n",
            "\n",
            "epoca 105 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0238\n",
            "0.02375227779858489\n",
            "\n",
            "epoca 106 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0236\n",
            "0.02356785642580348\n",
            "\n",
            "epoca 107 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0236\n",
            "0.023601735068799867\n",
            "\n",
            "epoca 108 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0237\n",
            "0.023696460688502223\n",
            "\n",
            "epoca 109 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.023577480037290148\n",
            "\n",
            "epoca 110 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0235\n",
            "0.023525754986050956\n",
            "\n",
            "epoca 111 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0235\n",
            "0.023546566452430175\n",
            "\n",
            "epoca 112 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0237\n",
            "0.023665088083188478\n",
            "\n",
            "epoca 113 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0238\n",
            "0.023751684742301583\n",
            "\n",
            "epoca 114 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0236\n",
            "0.02364936507048007\n",
            "\n",
            "epoca 115 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.0235561740215893\n",
            "\n",
            "epoca 116 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0236\n",
            "0.023590864034349197\n",
            "\n",
            "epoca 117 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0237\n",
            "0.02367723777003179\n",
            "\n",
            "epoca 118 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0236\n",
            "0.023606535563903554\n",
            "\n",
            "epoca 119 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0235\n",
            "0.02345474151739924\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 120 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0237\n",
            "0.02367937433205987\n",
            "\n",
            "epoca 121 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 223us/step - loss: 0.0237\n",
            "0.02368292604782461\n",
            "\n",
            "epoca 122 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0236\n",
            "0.02364115723790147\n",
            "\n",
            "epoca 123 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0644\n",
            "0.06438947867658708\n",
            "\n",
            "epoca 124 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0627\n",
            "0.0627151635972699\n",
            "\n",
            "epoca 125 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0550\n",
            "0.055014559781436115\n",
            "\n",
            "epoca 126 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0510\n",
            "0.05104751055818535\n",
            "\n",
            "epoca 127 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0475\n",
            "0.04746911842178581\n",
            "\n",
            "epoca 128 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0377\n",
            "0.03767987446014172\n",
            "\n",
            "epoca 129 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0257\n",
            "0.02566653510138401\n",
            "\n",
            "epoca 130 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0241\n",
            "0.024146667655523486\n",
            "\n",
            "epoca 131 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0237\n",
            "0.023716347357869726\n",
            "\n",
            "epoca 132 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 227us/step - loss: 0.0237\n",
            "0.023749813211329126\n",
            "\n",
            "epoca 133 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 229us/step - loss: 0.0237\n",
            "0.023715568389561067\n",
            "\n",
            "epoca 134 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 228us/step - loss: 0.0235\n",
            "0.023517170438977303\n",
            "\n",
            "epoca 135 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 228us/step - loss: 0.0235\n",
            "0.023510874589488178\n",
            "\n",
            "epoca 136 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 229us/step - loss: 0.0236\n",
            "0.023595910442600846\n",
            "\n",
            "epoca 137 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 227us/step - loss: 0.0237\n",
            "0.023651531753964235\n",
            "\n",
            "epoca 138 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0236\n",
            "0.02361170040842481\n",
            "\n",
            "epoca 139 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0234\n",
            "0.023385785078929924\n",
            "\n",
            "Saved model to disk\n",
            "\n",
            "\n",
            "epoca 140 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0235\n",
            "0.023490941424496342\n",
            "\n",
            "epoca 141 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0235\n",
            "0.023495040120251044\n",
            "\n",
            "epoca 142 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0235\n",
            "0.023534172261262643\n",
            "\n",
            "epoca 143 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0235\n",
            "0.023549311169379902\n",
            "\n",
            "epoca 144 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0234\n",
            "0.023419968257779176\n",
            "\n",
            "epoca 145 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.02361599351368662\n",
            "\n",
            "epoca 146 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 226us/step - loss: 0.0236\n",
            "0.023572620408932467\n",
            "\n",
            "epoca 147 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 224us/step - loss: 0.0237\n",
            "0.023659088551105795\n",
            "\n",
            "epoca 148 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0235\n",
            "0.023544166259709683\n",
            "\n",
            "epoca 149 de 4000\n",
            "Epoch 1/1\n",
            "57461/57461 [==============================] - 13s 225us/step - loss: 0.0236\n",
            "0.023616307427726524\n",
            "\n",
            "epoca 150 de 4000\n",
            "Epoch 1/1\n",
            "30464/57461 [==============>...............] - ETA: 6s - loss: 0.0915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8aee4ae1afc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistorial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_au\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_au\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-e7e4ad41c06d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, batch_size, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoca {} de {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontador\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m       \u001b[0mnloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7XxPE7YCm40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = load_model('autoencoder_definitivo.h5')\n",
        "encoder = load_model('encoder_definitivo.h5')\n",
        "decoder = load_model('decoder_definitivo.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjDmialrDIZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.save('/content/drive/My Drive/Autoencoder_definitivo/autoencoder_definitivo.h5')\n",
        "encoder.save('/content/drive/My Drive/Autoencoder_definitivo/encoder_definitivo.h5')\n",
        "decoder.save('/content/drive/My Drive/Autoencoder_definitivo/decoder_definitivo.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}